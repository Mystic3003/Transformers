{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5059014-a8c5-43e9-9118-36c685ef84b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPLETE STEP-BY-STEP PADDING & MASKING WALKTHROUGH\n",
      "================================================================================\n",
      "\n",
      "STEP 1: Original Variable-Length Sentences\n",
      "--------------------------------------------------------------------------------\n",
      "Sentences as text:\n",
      "  Sentence 0: 'The cat sat'\n",
      "  Sentence 1: 'Hello world'\n",
      "  Sentence 2: 'I love transformers models'\n",
      "\n",
      "Sentences as token IDs:\n",
      "  Sentence 0: [1, 2, 3]  (length=3)\n",
      "  Sentence 1: [4, 5]  (length=2)\n",
      "  Sentence 2: [6, 7, 8, 9]  (length=4)\n",
      "\n",
      "❌ Problem: Can't create tensor from different lengths!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPLETE STEP-BY-STEP PADDING & MASKING WALKTHROUGH\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# =============================================\n",
    "# STEP 1: Raw sentences (different lengths)\n",
    "# =============================================\n",
    "print(\"STEP 1: Original Variable-Length Sentences\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Example: 3 sentences with different lengths\n",
    "sentences_text = [\n",
    "    \"The cat sat\",      # 3 words\n",
    "    \"Hello world\",      # 2 words  \n",
    "    \"I love transformers models\"  # 4 words\n",
    "]\n",
    "\n",
    "# Convert to token IDs (pretend vocabulary mapping)\n",
    "vocab = {\"The\": 1, \"cat\": 2, \"sat\": 3, \"Hello\": 4, \"world\": 5, \n",
    "         \"I\": 6, \"love\": 7, \"transformers\": 8, \"models\": 9, \"<PAD>\": 0}\n",
    "\n",
    "sentences = [\n",
    "    [1, 2, 3],           # \"The cat sat\"\n",
    "    [4, 5],              # \"Hello world\"\n",
    "    [6, 7, 8, 9]         # \"I love transformers models\"\n",
    "]\n",
    "\n",
    "print(\"Sentences as text:\")\n",
    "for i, text in enumerate(sentences_text):\n",
    "    print(f\"  Sentence {i}: '{text}'\")\n",
    "print()\n",
    "\n",
    "print(\"Sentences as token IDs:\")\n",
    "for i, tokens in enumerate(sentences):\n",
    "    print(f\"  Sentence {i}: {tokens}  (length={len(tokens)})\")\n",
    "print()\n",
    "\n",
    "print(\"❌ Problem: Can't create tensor from different lengths!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3239d8-7fcd-4423-a56e-50f841385a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: Pad All Sentences to Same Length\n",
      "--------------------------------------------------------------------------------\n",
      "Max sentence length: 4\n",
      "Padding token ID: 0 (represents '<PAD>')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# STEP 2: Pad to same length\n",
    "# =============================================\n",
    "print(\"STEP 2: Pad All Sentences to Same Length\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "PAD_TOKEN = 0\n",
    "max_length = max(len(s) for s in sentences)  # = 4\n",
    "print(f\"Max sentence length: {max_length}\")\n",
    "print(f\"Padding token ID: {PAD_TOKEN} (represents '<PAD>')\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636d1a5c-ffc9-4489-9cd5-abe7bf3efba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0:\n",
      "  Original:      [1, 2, 3]\n",
      "  Padding added: [0]\n",
      "  Padded result: [1, 2, 3, 0]\n",
      "\n",
      "Sentence 1:\n",
      "  Original:      [4, 5]\n",
      "  Padding added: [0, 0]\n",
      "  Padded result: [4, 5, 0, 0]\n",
      "\n",
      "Sentence 2:\n",
      "  Original:      [6, 7, 8, 9]\n",
      "  Padding added: []\n",
      "  Padded result: [6, 7, 8, 9]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pad each sentence\n",
    "padded_sentences = []\n",
    "padding_info = []\n",
    "\n",
    "for i, sent in enumerate(sentences):\n",
    "    original_len = len(sent)\n",
    "    padding_needed = max_length - original_len\n",
    "    padded = sent + [PAD_TOKEN] * padding_needed\n",
    "    padded_sentences.append(padded)\n",
    "    padding_info.append((original_len, padding_needed))\n",
    "    \n",
    "    print(f\"Sentence {i}:\")\n",
    "    print(f\"  Original:      {sent}\")\n",
    "    print(f\"  Padding added: {[PAD_TOKEN] * padding_needed}\")\n",
    "    print(f\"  Padded result: {padded}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e207206-9a7c-4028-aec1-25f4c44de243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Now we can create a tensor!\n",
      "Batch shape: torch.Size([3, 4])\n",
      "Batch tensor:\n",
      "tensor([[1, 2, 3, 0],\n",
      "        [4, 5, 0, 0],\n",
      "        [6, 7, 8, 9]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensor\n",
    "batch = torch.tensor(padded_sentences)\n",
    "print(\"✅ Now we can create a tensor!\")\n",
    "print(f\"Batch shape: {batch.shape}\")\n",
    "print(\"Batch tensor:\")\n",
    "print(batch)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3bb418-cb80-4a79-b534-f03828808e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: Create Padding Mask\n",
      "--------------------------------------------------------------------------------\n",
      "Padding mask (True=real token, False=padding):\n",
      "tensor([[ True,  True,  True, False],\n",
      "        [ True,  True, False, False],\n",
      "        [ True,  True,  True,  True]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# STEP 3: Create padding mask\n",
    "# =============================================\n",
    "print(\"STEP 3: Create Padding Mask\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Mask: True (1) for real tokens, False (0) for padding\n",
    "padding_mask = (batch != PAD_TOKEN)\n",
    "print(\"Padding mask (True=real token, False=padding):\")\n",
    "print(padding_mask)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9749ba9-ecb7-4a65-bb07-fae383b39a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding mask as integers (1=real, 0=padding):\n",
      "tensor([[1, 1, 1, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [1, 1, 1, 1]], dtype=torch.int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to int for clarity\n",
    "padding_mask_int = padding_mask.int()\n",
    "print(\"Padding mask as integers (1=real, 0=padding):\")\n",
    "print(padding_mask_int)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13ad05fd-db2c-43fb-a165-610c33b06938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual representation:\n",
      "  Sentence 0:\n",
      "    Tokens: [1, 2, 3, 0]\n",
      "    Mask:   [1, 1, 1, 0]\n",
      "\n",
      "  Sentence 1:\n",
      "    Tokens: [4, 5, 0, 0]\n",
      "    Mask:   [1, 1, 0, 0]\n",
      "\n",
      "  Sentence 2:\n",
      "    Tokens: [6, 7, 8, 9]\n",
      "    Mask:   [1, 1, 1, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Visual representation:\")\n",
    "for i in range(len(sentences)):\n",
    "    tokens = padded_sentences[i]\n",
    "    mask = padding_mask_int[i].tolist()\n",
    "    print(f\"  Sentence {i}:\")\n",
    "    print(f\"    Tokens: {tokens}\")\n",
    "    print(f\"    Mask:   {mask}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1a03dac-6c20-4380-b771-daa39bde537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: Reshape Mask for Attention Broadcasting\n",
      "--------------------------------------------------------------------------------\n",
      "Current mask shape: torch.Size([3, 4])\n",
      "Need shape: (batch, 1, 1, seq_len) for broadcasting in attention\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# STEP 4: Reshape mask for attention\n",
    "# =============================================\n",
    "print(\"STEP 4: Reshape Mask for Attention Broadcasting\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"Current mask shape: {padding_mask_int.shape}\")  # (3, 4)\n",
    "print(\"Need shape: (batch, 1, 1, seq_len) for broadcasting in attention\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce07fd13-8903-4fe4-b0bd-6f86c1ebdf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After unsqueeze(1).unsqueeze(2): torch.Size([3, 1, 1, 4])\n",
      "original mask , mask for broadcasting tensor([[1, 1, 1, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [1, 1, 1, 1]], dtype=torch.int32) \n",
      " tensor([[[[1, 1, 1, 0]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1]]]], dtype=torch.int32)\n",
      "\n",
      "Attention mask for sentence 0:\n",
      "tensor([[[1, 1, 1, 0]]], dtype=torch.int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add dimensions for multi-head attention broadcasting\n",
    "attention_mask = padding_mask_int.unsqueeze(1).unsqueeze(2) ###\n",
    "print(f\"After unsqueeze(1).unsqueeze(2): {attention_mask.shape}\")\n",
    "print('original mask , mask for broadcasting',padding_mask_int ,'\\n', attention_mask)\n",
    "print()\n",
    "\n",
    "print(\"Attention mask for sentence 0:\")\n",
    "print(attention_mask[0])  # Shape: (1, 1, 4)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72654b09-e5dd-4084-a864-b9fa9a13505b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5: Create Fake Word Embeddings\n",
      "--------------------------------------------------------------------------------\n",
      "Embeddings shape: torch.Size([3, 4, 4])\n",
      "\n",
      "Embeddings for sentence 0 (first 2 tokens shown):\n",
      "tensor([[[ 0.0390,  1.2864, -0.0465,  0.1523],\n",
      "         [-0.0989, -0.0983, -1.5240, -0.6505],\n",
      "         [-0.7088, -0.3947, -0.8631,  0.6357],\n",
      "         [ 0.2402,  0.1570,  0.8318, -0.7455]],\n",
      "\n",
      "        [[-1.5385, -0.9676,  0.1291, -0.3060],\n",
      "         [ 0.3818, -1.7163,  0.4612, -1.4791],\n",
      "         [-0.7222, -0.1763,  0.1610,  0.2271],\n",
      "         [ 0.5986, -1.3758, -1.0151,  1.1532]],\n",
      "\n",
      "        [[-0.4889, -1.2062,  1.6661,  1.2652],\n",
      "         [-0.6652, -0.1572,  0.3248, -0.3875],\n",
      "         [ 0.1691, -0.0992, -0.9785,  1.0788],\n",
      "         [ 1.6241,  1.2240, -1.2637, -1.4149]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# STEP 5: Create fake embeddings\n",
    "# =============================================\n",
    "print(\"STEP 5: Create Fake Word Embeddings\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "d_model = 4  # Embedding dimension (tiny for demo)\n",
    "batch_size, seq_len = batch.shape\n",
    "\n",
    "# Create random embeddings for each token\n",
    "embeddings = torch.randn(batch_size, seq_len, d_model)\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")  # (3, 4, 4)\n",
    "print()\n",
    "\n",
    "print(\"Embeddings for sentence 0 (first 2 tokens shown):\")\n",
    "print(embeddings)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533c7c2b-d49c-4347-852b-8ba627c69005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# STEP 6: Compute attention scores (simplified)\n",
    "# =============================================\n",
    "print(\"STEP 6: Compute Attention Scores (Q @ K^T)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# For simplicity, use embeddings as Q and K\n",
    "Q = embeddings\n",
    "K = embeddings\n",
    "\n",
    "# Compute attention scores: Q @ K^T\n",
    "attention_scores = Q @ K.transpose(-2, -1) / math.sqrt(d_model)\n",
    "print(f\"Attention scores shape: {attention_scores.shape}\")  # (3, 4, 4)\n",
    "print()\n",
    "\n",
    "print(\"Attention scores for sentence 0 (BEFORE masking):\")\n",
    "print(attention_scores[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267da01-d314-4748-abcc-48abee8fe3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"  Row i = how token i scores against all tokens\")\n",
    "print(\"  attention_scores[0, i, j] = score of token i attending to token j\")\n",
    "print()\n",
    "\n",
    "# =============================================\n",
    "# STEP 7: Apply mask to attention scores\n",
    "# =============================================\n",
    "print(\"STEP 7: Apply Mask to Attention Scores\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"Mask for sentence 0:\")\n",
    "print(attention_mask[0].squeeze())  # [1, 1, 1, 1] for this sentence (no padding)\n",
    "print()\n",
    "\n",
    "print(\"Mask for sentence 1 (has 2 padding tokens):\")\n",
    "print(attention_mask[1].squeeze())  # [1, 1, 0, 0]\n",
    "print()\n",
    "\n",
    "# Apply mask: set padding positions to very negative value\n",
    "masked_attention_scores = attention_scores.clone()\n",
    "\n",
    "# Expand mask for broadcasting: (3, 1, 1, 4) → broadcasts to (3, 4, 4)\n",
    "mask_expanded = attention_mask.expand(-1, seq_len, -1, -1).squeeze(1)\n",
    "print(f\"Expanded mask shape: {mask_expanded.shape}\")  # (3, 4, 4)\n",
    "print()\n",
    "\n",
    "# Where mask=0, set score to -1e9\n",
    "masked_attention_scores.masked_fill_(mask_expanded == 0, -1e9)\n",
    "\n",
    "print(\"Attention scores for sentence 1 (AFTER masking):\")\n",
    "print(masked_attention_scores[1])\n",
    "print()\n",
    "print(\"Notice: Columns 2 and 3 (padding tokens) now have -1e9 values!\")\n",
    "print()\n",
    "\n",
    "# =============================================\n",
    "# STEP 8: Apply softmax\n",
    "# =============================================\n",
    "print(\"STEP 8: Apply Softmax to Get Attention Weights\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "attention_weights = torch.softmax(masked_attention_scores, dim=-1)\n",
    "print(f\"Attention weights shape: {attention_weights.shape}\")  # (3, 4, 4)\n",
    "print()\n",
    "\n",
    "print(\"Attention weights for sentence 1:\")\n",
    "print(attention_weights[1])\n",
    "print()\n",
    "\n",
    "print(\"Row sums (should be 1.0):\")\n",
    "print(attention_weights[1].sum(dim=-1))\n",
    "print()\n",
    "\n",
    "print(\"Detailed breakdown for sentence 1 token 0 (Hello):\")\n",
    "print(f\"  Attention to token 0 (Hello):       {attention_weights[1, 0, 0]:.6f}\")\n",
    "print(f\"  Attention to token 1 (world):       {attention_weights[1, 0, 1]:.6f}\")\n",
    "print(f\"  Attention to token 2 (<PAD>):       {attention_weights[1, 0, 2]:.6f}\")\n",
    "print(f\"  Attention to token 3 (<PAD>):       {attention_weights[1, 0, 3]:.6f}\")\n",
    "print(f\"  Sum: {attention_weights[1, 0].sum():.6f}\")\n",
    "print()\n",
    "print(\"✅ Padding tokens receive near-zero attention!\")\n",
    "print()\n",
    "\n",
    "# =============================================\n",
    "# STEP 9: Compute weighted values\n",
    "# =============================================\n",
    "print(\"STEP 9: Compute Weighted Sum of Values\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Use embeddings as values\n",
    "V = embeddings\n",
    "\n",
    "# Weighted sum: attention_weights @ V\n",
    "context = attention_weights @ V\n",
    "print(f\"Context vectors shape: {context.shape}\")  # (3, 4, 4)\n",
    "print()\n",
    "\n",
    "print(\"Context vector for sentence 1, token 0 (Hello):\")\n",
    "print(context[1, 0])\n",
    "print()\n",
    "\n",
    "print(\"This context vector is:\")\n",
    "print(f\"  {attention_weights[1, 0, 0]:.3f} × embedding(Hello)\")\n",
    "print(f\"  + {attention_weights[1, 0, 1]:.3f} × embedding(world)\")\n",
    "print(f\"  + {attention_weights[1, 0, 2]:.3f} × embedding(<PAD>)\")\n",
    "print(f\"  + {attention_weights[1, 0, 3]:.3f} × embedding(<PAD>)\")\n",
    "print()\n",
    "print(\"Since padding weights ≈ 0, context ignores padding! ✅\")\n",
    "print()\n",
    "\n",
    "# =============================================\n",
    "# STEP 10: Summary visualization\n",
    "# =============================================\n",
    "print(\"STEP 10: Final Summary Visualization\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for sent_idx in range(batch_size):\n",
    "    print(f\"\\nSentence {sent_idx}: {sentences_text[sent_idx]}\")\n",
    "    print(f\"  Tokens: {padded_sentences[sent_idx]}\")\n",
    "    print(f\"  Mask:   {padding_mask_int[sent_idx].tolist()}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"  Attention matrix (query → key):\")\n",
    "    print(\"         Tok0   Tok1   Tok2   Tok3\")\n",
    "    for i in range(seq_len):\n",
    "        weights_str = \"  \".join([f\"{w:.3f}\" for w in attention_weights[sent_idx, i]])\n",
    "        print(f\"    Tok{i} [{weights_str}]\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY TAKEAWAYS:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"1. Padding makes variable-length sequences same length → tensor creation ✅\")\n",
    "print(\"2. Mask identifies real tokens (1) vs padding (0)\")\n",
    "print(\"3. Attention scores for padding set to -1e9\")\n",
    "print(\"4. After softmax, padding attention becomes ~0\")\n",
    "print(\"5. Context vectors ignore padding tokens completely ✅\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0cf8c6-ec07-40e2-baf6-581aa0edf1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
