{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd70e4e-0b4f-47b7-80cf-80d32321e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. The FeedForwardBlock class \n",
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)    # W1: d_model → d_ff, B1: d_ff\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)    # W2: d_ff → d_model, B2: d_model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Shape: (batch, seq_len, d_model) → (batch, seq_len, d_ff) → (batch, seq_len, d_model)\n",
    "        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00f66955-62ee-4796-8363-df99ba727bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRANSFORMER FEEDFORWARD BLOCK STEP-BY-STEP ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== TRANSFORMER FEEDFORWARD BLOCK STEP-BY-STEP ===\\n\")\n",
    "\n",
    "# 2. Hyperparameters (tiny for easy reading)\n",
    "d_model = 4    # Input/output dimension\n",
    "d_ff = 8       # Hidden dimension (usually 4x larger)\n",
    "dropout = 0.1  # Dropout rate\n",
    "batch_size = 2\n",
    "seq_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f6c9ce-ca5f-4d10-b1f4-59870b25fbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 - Input x shape: torch.Size([2, 3, 4])\n",
      "Input x:\n",
      " tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Create tiny sample input: (batch=2, seq=3, d_model=4)\n",
    "x = torch.arange(24).float().reshape(batch_size, seq_len, d_model)\n",
    "print(\"Step 1 - Input x shape:\", x.shape)\n",
    "print(\"Input x:\\n\", x)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d926c3f-a63b-4578-b251-7025d2596175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 - Created FeedForwardBlock(d_model=4, d_ff=8)\n",
      "linear_1 weights shape: torch.Size([8, 4])\n",
      "linear_2 weights shape: torch.Size([4, 8])\n",
      "linear_1 bias shape: torch.Size([8])\n",
      "linear_2 bias shape: torch.Size([4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Create the FeedForward block\n",
    "ff_block = FeedForwardBlock(d_model=d_model, d_ff=d_ff, dropout=dropout)\n",
    "print(\"Step 2 - Created FeedForwardBlock(d_model=4, d_ff=8)\")\n",
    "print(\"linear_1 weights shape:\", ff_block.linear_1.weight.shape)  # [8, 4]\n",
    "print(\"linear_2 weights shape:\", ff_block.linear_2.weight.shape)  # [4, 8]\n",
    "print(\"linear_1 bias shape:\", ff_block.linear_1.bias.shape)  # [8]\n",
    "print(\"linear_2 bias shape:\", ff_block.linear_2.bias.shape)  # [4]\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aa2f0c4-62ea-403e-a8c4-ebea24233dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original input : tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.]]])\n",
      "Step 3 - After linear_1(x): shape torch.Size([2, 3, 8])\n",
      "Output after passing through the first linear layer tensor([[[-2.2255, -0.1673,  1.5966, -1.5649, -0.1716,  0.4000,  0.1738,\n",
      "          -0.5781],\n",
      "         [-3.7350,  0.6146,  4.0118, -2.1933,  1.8573,  3.0914,  3.0974,\n",
      "           0.1763],\n",
      "         [-5.2446,  1.3965,  6.4269, -2.8217,  3.8862,  5.7829,  6.0210,\n",
      "           0.9307]],\n",
      "\n",
      "        [[-6.7541,  2.1784,  8.8421, -3.4501,  5.9151,  8.4744,  8.9446,\n",
      "           1.6852],\n",
      "         [-8.2637,  2.9603, 11.2573, -4.0785,  7.9440, 11.1658, 11.8682,\n",
      "           2.4396],\n",
      "         [-9.7732,  3.7423, 13.6725, -4.7069,  9.9728, 13.8573, 14.7918,\n",
      "           3.1940]]], grad_fn=<ViewBackward0>)\n",
      "hidden (first few values):\n",
      " tensor([[[-2.2255, -0.1673],\n",
      "         [-3.7350,  0.6146],\n",
      "         [-5.2446,  1.3965]],\n",
      "\n",
      "        [[-6.7541,  2.1784],\n",
      "         [-8.2637,  2.9603],\n",
      "         [-9.7732,  3.7423]]], grad_fn=<SliceBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. STEP 1: linear_1(x) - First linear expansion\n",
    "# nn.Linear: x @ W^T + b  (matrix multiplication + bias)\n",
    "# Shape: (2,3,4) → (2,3,8)\n",
    "print('original input :',x)\n",
    "hidden = ff_block.linear_1(x)\n",
    "print(\"Step 3 - After linear_1(x): shape\", hidden.shape)\n",
    "print('Output after passing through the first linear layer',hidden)\n",
    "print(\"hidden (first few values):\\n\", hidden[:,:,:2])  # Show first 2 dims for readability\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21cbd3d0-f4e8-40d3-9744-1a156ba9bdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 - After ReLU: kills negatives\n",
      "Before ReLU (had negatives): 15 negative values\n",
      "After ReLU (all non-negative): 0 negative values\n",
      "Output after Relu tensor([[[ 0.0000,  0.0000,  1.5966,  0.0000,  0.0000,  0.4000,  0.1738,\n",
      "           0.0000],\n",
      "         [ 0.0000,  0.6146,  4.0118,  0.0000,  1.8573,  3.0914,  3.0974,\n",
      "           0.1763],\n",
      "         [ 0.0000,  1.3965,  6.4269,  0.0000,  3.8862,  5.7829,  6.0210,\n",
      "           0.9307]],\n",
      "\n",
      "        [[ 0.0000,  2.1784,  8.8421,  0.0000,  5.9151,  8.4744,  8.9446,\n",
      "           1.6852],\n",
      "         [ 0.0000,  2.9603, 11.2573,  0.0000,  7.9440, 11.1658, 11.8682,\n",
      "           2.4396],\n",
      "         [ 0.0000,  3.7423, 13.6725,  0.0000,  9.9728, 13.8573, 14.7918,\n",
      "           3.1940]]], grad_fn=<ReluBackward0>)\n",
      "relu_out (first few):\n",
      " tensor([[[0.0000, 0.0000],\n",
      "         [0.0000, 0.6146],\n",
      "         [0.0000, 1.3965]],\n",
      "\n",
      "        [[0.0000, 2.1784],\n",
      "         [0.0000, 2.9603],\n",
      "         [0.0000, 3.7423]]], grad_fn=<SliceBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. STEP 2: torch.relu() - ReLU activation\n",
    "# ReLU: max(0, x) - kills all negative values\n",
    "# Shape unchanged: (2,3,8)\n",
    "relu_out = torch.relu(hidden)\n",
    "print(\"Step 4 - After ReLU: kills negatives\")\n",
    "print(\"Before ReLU (had negatives):\", (hidden < 0).sum().item(), \"negative values\")\n",
    "print(\"After ReLU (all non-negative):\", (relu_out < 0).sum().item(), \"negative values\")\n",
    "print('Output after Relu',relu_out)\n",
    "print(\"relu_out (first few):\\n\", relu_out[:,:,:2])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f15a14d-da26-4856-be17-4cd87a973e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before droput tensor([[[ 0.0000,  0.0000,  1.5966,  0.0000,  0.0000,  0.4000,  0.1738,\n",
      "           0.0000],\n",
      "         [ 0.0000,  0.6146,  4.0118,  0.0000,  1.8573,  3.0914,  3.0974,\n",
      "           0.1763],\n",
      "         [ 0.0000,  1.3965,  6.4269,  0.0000,  3.8862,  5.7829,  6.0210,\n",
      "           0.9307]],\n",
      "\n",
      "        [[ 0.0000,  2.1784,  8.8421,  0.0000,  5.9151,  8.4744,  8.9446,\n",
      "           1.6852],\n",
      "         [ 0.0000,  2.9603, 11.2573,  0.0000,  7.9440, 11.1658, 11.8682,\n",
      "           2.4396],\n",
      "         [ 0.0000,  3.7423, 13.6725,  0.0000,  9.9728, 13.8573, 14.7918,\n",
      "           3.1940]]], grad_fn=<ReluBackward0>)\n",
      "Linear Layer - Relu, before droput : 15 zeros\n",
      "******************************\n",
      "Step 5 - After dropout (training mode):\n",
      "Some values zeroed out: 21 zeros\n",
      "after droput tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4444,  0.0000,\n",
      "           0.0000],\n",
      "         [ 0.0000,  0.6829,  4.4575,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.1959],\n",
      "         [ 0.0000,  1.5517,  7.1411,  0.0000,  4.3180,  6.4254,  6.6900,\n",
      "           1.0341]],\n",
      "\n",
      "        [[ 0.0000,  2.4205,  9.8246,  0.0000,  6.5723,  9.4159,  9.9384,\n",
      "           1.8724],\n",
      "         [ 0.0000,  3.2893, 12.5081,  0.0000,  8.8266, 12.4065, 13.1869,\n",
      "           2.7106],\n",
      "         [ 0.0000,  4.1581,  0.0000,  0.0000, 11.0809, 15.3970, 16.4353,\n",
      "           3.5489]]], grad_fn=<MulBackward0>)\n",
      "******************************\n",
      "dropout_out (first few):\n",
      " tensor([[[0.0000, 0.0000],\n",
      "         [0.0000, 0.6829],\n",
      "         [0.0000, 1.5517]],\n",
      "\n",
      "        [[0.0000, 2.4205],\n",
      "         [0.0000, 3.2893],\n",
      "         [0.0000, 4.1581]]], grad_fn=<SliceBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. STEP 3: self.dropout() - Randomly zero some values during training\n",
    "# nn.Dropout: randomly sets p% of elements to 0, scales rest by 1/(1-p)\n",
    "# Shape unchanged: (2,3,8)\n",
    "dropout_out = ff_block.dropout(relu_out)\n",
    "print('before droput',relu_out)\n",
    "print(\"Linear Layer - Relu, before droput :\", (relu_out == 0).sum().item(), \"zeros\")\n",
    "print(\"*\"*30)\n",
    "print(\"Step 5 - After dropout (training mode):\")\n",
    "print(\"Some values zeroed out:\", (dropout_out == 0).sum().item(), \"zeros\")\n",
    "print('after droput',dropout_out)\n",
    "print(\"*\"*30)\n",
    "print(\"dropout_out (first few):\\n\", dropout_out[:,:,:2])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "083ec405-d5a1-4b73-bba0-f9cb770288e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6 - After linear_2(): back to d_model=4\n",
      "Final output shape: torch.Size([2, 3, 4])\n",
      "Final output:\n",
      " tensor([[[-0.1719,  0.0875,  0.0182,  0.1130],\n",
      "         [-0.5034,  0.4950, -1.1832,  0.4113],\n",
      "         [-0.4243,  0.4544,  1.0347,  1.3692]],\n",
      "\n",
      "        [[-0.4609,  0.3650,  1.8865,  1.9850],\n",
      "         [-0.4975,  0.2756,  2.7382,  2.6008],\n",
      "         [ 0.8554, -2.1799,  8.1412,  2.1299]]], grad_fn=<ViewBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. STEP 4: linear_2() - Second linear projection back to d_model\n",
    "# Shape: (2,3,8) → (2,3,4)\n",
    "output = ff_block.linear_2(dropout_out)\n",
    "print(\"Step 6 - After linear_2(): back to d_model=4\")\n",
    "print(\"Final output shape:\", output.shape)\n",
    "print(\"Final output:\\n\", output)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce1bdcb0-a1b0-40fc-89e0-2eadbb8a7e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7 - END-TO-END: ff_block(x)\n",
      "direct_output shape: torch.Size([2, 3, 4])\n",
      "Matches step-by-step? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. END-TO-END: Just call the module!\n",
    "print(\"Step 7 - END-TO-END: ff_block(x)\")\n",
    "direct_output = ff_block(x)\n",
    "print(\"direct_output shape:\", direct_output.shape)\n",
    "print(\"Matches step-by-step?\", torch.allclose(output, direct_output))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82c66b1d-c713-43a1-85b7-2dd8b6225d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8 - INPUT vs OUTPUT comparison:\n",
      "Input range:   0.0 to 23.0\n",
      "Output range: -2.1798744201660156 to 8.14122200012207\n",
      "Output is NON-LINEAR transformation of input!\n"
     ]
    }
   ],
   "source": [
    "# 10. Compare input vs output (shows transformation)\n",
    "print(\"Step 8 - INPUT vs OUTPUT comparison:\")\n",
    "print(\"Input range:  \", x.min().item(), \"to\", x.max().item())\n",
    "print(\"Output range:\", output.min().item(), \"to\", output.max().item())\n",
    "print(\"Output is NON-LINEAR transformation of input!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f17b43-6ce3-478b-a658-ddd9e94b6bb4",
   "metadata": {},
   "source": [
    "Step 3 - After linear_1: (2,3,8)  ← EXPANDED from 4→8 dims\n",
    "Step 4 - After ReLU: all ≥0      ← NON-LINEARITY introduced\n",
    "Step 5 - After dropout: ~10% zeros ← REGULARIZATION\n",
    "Step 6 - After linear_2: (2,3,4) ← BACK to original dim\n",
    "Key insights from \"Attention is All You Need\"\n",
    "Paper reference (Section 3.3):\n",
    "FFN(x) = max(0, xW₁ + b₁)W₂ + b₂\n",
    "\n",
    "Expands to higher dimension (d_ff = 2048 typically, 4x d_model=512)\n",
    "\n",
    "ReLU adds non-linearity\n",
    "\n",
    "Contracts back to d_model\n",
    "\n",
    "Pointwise (independent per position)\n",
    "\n",
    "Why this design?\n",
    "Expansion: More capacity for complex transformations\n",
    "\n",
    "ReLU: Non-linearity (linear→linear = boring)\n",
    "\n",
    "Dropout: Prevents overfitting\n",
    "\n",
    "Back to d_model: Compatible with attention residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb499e9d-f2f4-466b-a233-ec37fae87c83",
   "metadata": {},
   "source": [
    "## Understanding Importance of Bias Term "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c407c7b4-afc2-44b5-a0e3-2388e2861721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without bias at (0,0): 0.0\n"
     ]
    }
   ],
   "source": [
    "# NO BIAS: y = w1*x1 + w2*x2\n",
    "# All decision boundaries MUST pass through (0,0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x1 = np.array([1, 2, 3])\n",
    "x2 = np.array([2, 4, 6])\n",
    "y = np.array([0, 1, 1])  # Want to separate these\n",
    "\n",
    "# Without bias: line must go through origin\n",
    "w1, w2 = 1, 0.5\n",
    "line_no_bias = w1 * x1 + w2 * x2  # Always passes through (0,0)\n",
    "print(\"Without bias at (0,0):\", w1*0 + w2*0)  # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59f41778-af03-4a64-8f1a-0c358246b427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With bias at (0,0): -1.0\n"
     ]
    }
   ],
   "source": [
    "# Problem: If your data doesn't cluster around origin, no-bias model struggles.\n",
    "\n",
    "# WITH bias: Can shift anywhere\n",
    "# python\n",
    "# WITH BIAS: y = w1*x1 + w2*x2 + b\n",
    "b = -1.0  # Shift the line down\n",
    "line_with_bias = w1 * x1 + w2 * x2 + b\n",
    "print(\"With bias at (0,0):\", b)  # -1.0 (shifted!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68db0a39-1fcc-4f90-bc2b-a87b74d8d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In neural networks (your FeedForward)\n",
    "# Each nn.Linear(d_model, d_ff) automatically includes bias:\n",
    "\n",
    "linear_1 = nn.Linear(4, 8)  # Has weight (8,4) + bias (8,)\n",
    "# Computation: x @ W^T + b  ← b shifts every output neuron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8959c31b-ce7d-4edc-a15c-23f9c3bdf66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "Output after FFN tensor([[[ 0.0029, -0.0089,  0.2006, -0.1386],\n",
      "         [ 0.0018, -0.0075,  0.2000, -0.1376],\n",
      "         [ 0.0029, -0.0089,  0.2006, -0.1386]],\n",
      "\n",
      "        [[ 0.0979,  0.0076,  0.2264, -0.2689],\n",
      "         [ 0.0029, -0.0089,  0.2006, -0.1386],\n",
      "         [ 0.0370,  0.0981,  0.0927, -0.2013]]], grad_fn=<ViewBackward0>)\n",
      "Input all zeros → Output: tensor([ 0.0029, -0.0089,  0.2006, -0.1386], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Without bias (nn.Linear(..., bias=False)):\n",
    "\n",
    "# hidden[i] = sum(x[j] * W[i,j])  # Must be 0 when x=0\n",
    "# With bias:\n",
    "\n",
    "# hidden[i] = sum(x[j] * W[i,j]) + b[i]  # Can be anything when x=0\n",
    "\n",
    "x_all_zero = torch.zeros(2, 3, 4)  # All inputs = 0\n",
    "print('Input Tensor',x_all_zero)\n",
    "ff_block = FeedForwardBlock(4, 8, 0.1) ## input dim , hidden dim , dropout prob\n",
    "zero_output = ff_block(x_all_zero)\n",
    "print('Output after FFN',zero_output)\n",
    "print(\"Input all zeros → Output:\", zero_output[0,0])  # NOT zero! Thanks to biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126379ac-4557-48d6-8bc8-e025f798b744",
   "metadata": {},
   "source": [
    "Biases ensure even zero-input produces meaningful activation.\n",
    "\n",
    "Why biases matter in Transformers\n",
    "Residual connections: x + FF(x) needs FF(x) to have flexibility\n",
    "\n",
    "Non-zero activations: Even if attention output is small, FF can still activate\n",
    "\n",
    "Shift invariance: Model learns patterns regardless of input scale/origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e695f-c8bc-4d1b-b525-54513d0ec627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
